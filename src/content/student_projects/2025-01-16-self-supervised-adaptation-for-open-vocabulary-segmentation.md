---
title: Self-supervised Adaptation for Open-Vocabulary Segmentation
type: master thesis
visible: true
image: /projects/opendas.jpg
---
Multimodal Large Language Models (MLLM) have pushed the applicability of scene understanding in robotics to new limits. They allow to directly link natural language instructions to robotic scene understanding. Sometimes however, MLLMs trained on internet data have troubles to understand more domain-specific language queries, such as "bring me the 9er wrench" or "pick all the plants that are not beta vulgaris". This project builds up on prior work that developed a mechanism to adapt open-vocabulary methods to new words and visual appearances ([OpenDAS](https://open-das.github.io)). Currently, the method is impractical as it requires a lot of densely annotated images from the target domain. We want to develop mechanisms that allow to do such adaptation in a self-supervised way, e.g. by letting the robot look at the same object from multiple viewpoints and enforcing consistency of representation.

## Requirements
Experience with python and pytorch.

## Contact
Please send your CV and transcript to blumh@uni-bonn.de